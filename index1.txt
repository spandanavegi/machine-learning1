import sklearn
print('sklearn: {}'.format(sklearn.__version__))
python: 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0]
scipy: 1.4.1
numpy: 1.16.1
matplotlib: 3.0.3
pandas: 0.25.0
sklearn: 0.20.2
import pandas
from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn import model_selection
from sklearn.ensemble import VotingClassifier
​
names
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv"
names = ['sepal-length','sepal-width','petal-length','petal-widith','class']
dataset = read_csv(url,names=names)
.shape
print(dataset.shape)
(150, 5)
print(dataset.head(20))
    sepal-length  sepal-width  petal-length  petal-widith        class
0            5.1          3.5           1.4           0.2  Iris-setosa
1            4.9          3.0           1.4           0.2  Iris-setosa
2            4.7          3.2           1.3           0.2  Iris-setosa
3            4.6          3.1           1.5           0.2  Iris-setosa
4            5.0          3.6           1.4           0.2  Iris-setosa
5            5.4          3.9           1.7           0.4  Iris-setosa
6            4.6          3.4           1.4           0.3  Iris-setosa
7            5.0          3.4           1.5           0.2  Iris-setosa
8            4.4          2.9           1.4           0.2  Iris-setosa
9            4.9          3.1           1.5           0.1  Iris-setosa
10           5.4          3.7           1.5           0.2  Iris-setosa
11           4.8          3.4           1.6           0.2  Iris-setosa
12           4.8          3.0           1.4           0.1  Iris-setosa
13           4.3          3.0           1.1           0.1  Iris-setosa
14           5.8          4.0           1.2           0.2  Iris-setosa
15           5.7          4.4           1.5           0.4  Iris-setosa
16           5.4          3.9           1.3           0.4  Iris-setosa
17           5.1          3.5           1.4           0.3  Iris-setosa
18           5.7          3.8           1.7           0.3  Iris-setosa
19           5.1          3.8           1.5           0.3  Iris-setosa
print(dataset.groupby('class').size())
class
Iris-setosa        50
Iris-versicolor    50
Iris-virginica     50
dtype: int64
box
#univarientplot
dataset.plot(kind='box', subplots=True,layout=(2,2),sharex=False,sharey=False)
pyplot.show()

#histogram
dataset.hist()
pyplot.show()

#multivarient plots
scatter_matrix(dataset)
pyplot.show()

_
#creating a validation dataset
array = dataset.values
X= array[:, 0:4]
Y= array[:, 4]
X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size =0.2, random_state=1)
models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('LDA',LinearDiscriminantAnalysis()))
models.append(('KNN',KNeighborsClassifier()))
models.append(('NB',GaussianNB()))
models.append(('SVM',SVC(gamma='auto')))
#evalute the correct models
results=[]
names=[]
for name, model in models:
    kfold = StratifiedKFold(n_splits=10, random_state=1)
    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))
​
LR: 0.960897 (0.052113)
LDA: 0.973974 (0.040110)
KNN: 0.957191 (0.043263)
NB: 0.948858 (0.056322)
SVM: 0.983974 (0.032083)
s
pyplot.boxplot(results, labels=names)
pyplot.title('Algorithm Comparison')
pyplot.show()

model=SVC(gamma='auto')
model.fit(X_train,Y_train)
predictions = model.predict(X_validation)
​
,predictions
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix)
print(classification_report(Y_validation,predictions))
0.9666666666666667
<function confusion_matrix at 0x7f42e65c90d0>
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        11
Iris-versicolor       1.00      0.92      0.96        13
 Iris-virginica       0.86      1.00      0.92         6

      micro avg       0.97      0.97      0.97        30
      macro avg       0.95      0.97      0.96        30
   weighted avg       0.97      0.97      0.97        30

​
